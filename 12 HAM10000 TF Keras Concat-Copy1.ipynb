{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_train = pd.read_csv('./datasets/skin-cancer-mnist-ham10000/HAM10000_metadata_cleansed_train.csv',sep=',')\n",
    "csv_test = pd.read_csv('./datasets/skin-cancer-mnist-ham10000/HAM10000_metadata_cleansed_test.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_cat = {'bkl':0, 'nv':1, 'df':2, 'mel':3, 'vasc':4, 'bcc':5, 'akiec':6}\n",
    "dx_type_cat = {'histo':0, 'follow_up':.3, 'consensus':.6, 'confocal':.9}\n",
    "sex_cat = {'male':0, 'female':1, 'unknown':.5}\n",
    "localization_cat = {'back':0, 'face':.07, 'lower extremity':.14, 'trunk':.21, 'abdomen':.28, 'upper extremity':.35,\n",
    "                    'foot':.42, 'scalp':.49, 'unknown':.56, 'ear':.63, 'hand':.7, 'chest':.77, 'neck':.84,\n",
    "                    'genital':.91, 'acral':.98}\n",
    "\n",
    "csv_train.age = csv_train.age.astype(float)\n",
    "csv_train.age = csv_train.age/np.max(csv_train.age)\n",
    "\n",
    "csv_train.dx = csv_train.dx.map(dx_cat).astype(float)\n",
    "csv_train.dx_type = csv_train.dx_type.map(dx_type_cat).astype(float)\n",
    "csv_train.sex = csv_train.sex.map(sex_cat).astype(float)\n",
    "csv_train.localization = csv_train.localization.map(localization_cat).astype(float)\n",
    "\n",
    "csv_test.age = csv_test.age.astype(float)\n",
    "csv_test.age = csv_test.age/np.max(csv_test.age)\n",
    "\n",
    "csv_test.dx = csv_test.dx.map(dx_cat).astype(float)\n",
    "csv_test.dx_type = csv_test.dx_type.map(dx_type_cat).astype(float)\n",
    "csv_test.sex = csv_test.sex.map(sex_cat).astype(float)\n",
    "csv_test.localization = csv_test.localization.map(localization_cat).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HAM_0000005</td>\n",
       "      <td>ISIC_0025577</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HAM_0000005</td>\n",
       "      <td>ISIC_0030591</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>HAM_0000005</td>\n",
       "      <td>ISIC_0024579</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>HAM_0000005</td>\n",
       "      <td>ISIC_0029638</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>HAM_0000020</td>\n",
       "      <td>ISIC_0031922</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>HAM_0000193</td>\n",
       "      <td>ISIC_0030877</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>HAM_0000193</td>\n",
       "      <td>ISIC_0027950</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>HAM_0000239</td>\n",
       "      <td>ISIC_0033866</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>HAM_0000239</td>\n",
       "      <td>ISIC_0032854</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>HAM_0000356</td>\n",
       "      <td>ISIC_0026171</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx  dx_type       age  sex  localization\n",
       "0  HAM_0000005  ISIC_0025577  6.0      0.0  0.882353  1.0          0.14\n",
       "1  HAM_0000005  ISIC_0030591  6.0      0.0  0.882353  1.0          0.14\n",
       "2  HAM_0000005  ISIC_0024579  6.0      0.0  0.882353  1.0          0.14\n",
       "3  HAM_0000005  ISIC_0029638  6.0      0.0  0.882353  1.0          0.14\n",
       "4  HAM_0000020  ISIC_0031922  6.0      0.0  0.705882  1.0          0.07\n",
       "5  HAM_0000193  ISIC_0030877  6.0      0.0  0.705882  1.0          0.07\n",
       "6  HAM_0000193  ISIC_0027950  6.0      0.0  0.705882  1.0          0.07\n",
       "7  HAM_0000239  ISIC_0033866  6.0      0.0  0.941176  0.0          0.07\n",
       "8  HAM_0000239  ISIC_0032854  6.0      0.0  0.941176  0.0          0.07\n",
       "9  HAM_0000356  ISIC_0026171  6.0      0.0  0.705882  1.0          0.07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(csv_train.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-balance data if needed\n",
    "\n",
    "csv_train = csv_train.append(csv_train.loc[csv_train['dx'] == 2.0])\n",
    "csv_train = csv_train.append(csv_train.loc[csv_train['dx'] == 2.0])\n",
    "csv_train = csv_train.append(csv_train.loc[csv_train['dx'] == 4.0])\n",
    "csv_train = csv_train.append(csv_train.loc[csv_train['dx'] == 4.0])\n",
    "csv_train = csv_train.append(csv_train.loc[csv_train['dx'] == 6.0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a 100% sample randomised\n",
    "\n",
    "csv_train = csv_train.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2834</td>\n",
       "      <td>HAM_0006828</td>\n",
       "      <td>ISIC_0031977</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5719</td>\n",
       "      <td>HAM_0003246</td>\n",
       "      <td>ISIC_0029049</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1815</td>\n",
       "      <td>HAM_0005663</td>\n",
       "      <td>ISIC_0028735</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5144</td>\n",
       "      <td>HAM_0002581</td>\n",
       "      <td>ISIC_0026544</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HAM_0000005</td>\n",
       "      <td>ISIC_0030591</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3213</td>\n",
       "      <td>HAM_0000412</td>\n",
       "      <td>ISIC_0032706</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7264</td>\n",
       "      <td>HAM_0005016</td>\n",
       "      <td>ISIC_0027045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535</td>\n",
       "      <td>HAM_0003690</td>\n",
       "      <td>ISIC_0034155</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8093</td>\n",
       "      <td>HAM_0006007</td>\n",
       "      <td>ISIC_0031737</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3368</td>\n",
       "      <td>HAM_0000589</td>\n",
       "      <td>ISIC_0027103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id      image_id   dx  dx_type       age  sex  localization\n",
       "2834  HAM_0006828  ISIC_0031977  3.0      0.0  1.000000  0.0          0.00\n",
       "5719  HAM_0003246  ISIC_0029049  1.0      0.0  0.000000  0.0          0.63\n",
       "1815  HAM_0005663  ISIC_0028735  2.0      0.6  0.352941  0.0          0.14\n",
       "5144  HAM_0002581  ISIC_0026544  1.0      0.0  0.470588  0.0          0.00\n",
       "1     HAM_0000005  ISIC_0030591  6.0      0.0  0.882353  1.0          0.14\n",
       "3213  HAM_0000412  ISIC_0032706  1.0      0.6  0.823529  0.0          0.21\n",
       "7264  HAM_0005016  ISIC_0027045  1.0      0.0  0.705882  0.0          0.00\n",
       "535   HAM_0003690  ISIC_0034155  5.0      0.0  0.529412  1.0          0.56\n",
       "8093  HAM_0006007  ISIC_0031737  1.0      0.3  0.529412  1.0          0.21\n",
       "3368  HAM_0000589  ISIC_0027103  1.0      0.0  0.176471  1.0          0.84"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(csv_train.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your X and Y train and test data up in Pandas - Example \n",
    "\n",
    "X_train_data = csv_train.drop(['dx_type','lesion_id', 'image_id', 'dx'],axis=1)\n",
    "Y_train_data = csv_train['dx']\n",
    "\n",
    "X_test_data = csv_test.drop(['dx_type','lesion_id', 'image_id', 'dx'],axis=1)\n",
    "Y_test_data = csv_test['dx']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define where you are reading images from, here the column of the CSV file\n",
    "# with the name of the image (randomised and in the same order as above)\n",
    "\n",
    "X_train_img = csv_train['image_id']\n",
    "\n",
    "X_test_img = csv_test['image_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder = './datasets/skin-cancer-mnist-ham10000/HAM10000_images_s/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-shape and pre-process train images using OpenCV\n",
    "\n",
    "X_train = []\n",
    "for image_get in X_train_img:\n",
    "    img_train = cv2.imread(img_folder + '{}.jpg'.format(image_get))\n",
    "    \n",
    "    img_train = cv2.resize(img_train,(100,75))\n",
    "    \n",
    "    # img_train = img_train[0:224,38:262] # What does this do???\n",
    "\n",
    "    R,G,B = cv2.split(img_train)\n",
    "    R_new = cv2.equalizeHist(R)\n",
    "    G_new = cv2.equalizeHist(G)\n",
    "    B_new = cv2.equalizeHist(B)\n",
    "\n",
    "    img_train = cv2.merge([R_new,G_new,B_new])\n",
    "    img_train = cv2.GaussianBlur(img_train,(5,5),0)\n",
    "    \n",
    "    X_train.append(img_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[166, 231, 225],\n",
       "         [176, 236, 230],\n",
       "         [197, 244, 237],\n",
       "         ...,\n",
       "         [238, 232, 215],\n",
       "         [225, 221, 221],\n",
       "         [216, 213, 220]],\n",
       " \n",
       "        [[168, 234, 228],\n",
       "         [177, 237, 232],\n",
       "         [196, 245, 236],\n",
       "         ...,\n",
       "         [237, 232, 219],\n",
       "         [223, 219, 222],\n",
       "         [214, 210, 219]],\n",
       " \n",
       "        [[170, 238, 234],\n",
       "         [178, 241, 236],\n",
       "         [194, 246, 235],\n",
       "         ...,\n",
       "         [234, 232, 227],\n",
       "         [218, 215, 225],\n",
       "         [209, 204, 221]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[200, 196, 171],\n",
       "         [198, 202, 171],\n",
       "         [194, 213, 172],\n",
       "         ...,\n",
       "         [120, 145, 184],\n",
       "         [119, 144, 183],\n",
       "         [119, 143, 184]],\n",
       " \n",
       "        [[201, 183, 166],\n",
       "         [200, 192, 168],\n",
       "         [198, 210, 173],\n",
       "         ...,\n",
       "         [112, 130, 165],\n",
       "         [109, 127, 163],\n",
       "         [108, 127, 165]],\n",
       " \n",
       "        [[201, 175, 159],\n",
       "         [201, 186, 163],\n",
       "         [200, 208, 171],\n",
       "         ...,\n",
       "         [110, 125, 158],\n",
       "         [106, 122, 157],\n",
       "         [105, 122, 161]]], dtype=uint8)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Numpy array\n",
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[166, 231, 225],\n",
       "         [176, 236, 230],\n",
       "         [197, 244, 237],\n",
       "         ...,\n",
       "         [238, 232, 215],\n",
       "         [225, 221, 221],\n",
       "         [216, 213, 220]],\n",
       "\n",
       "        [[168, 234, 228],\n",
       "         [177, 237, 232],\n",
       "         [196, 245, 236],\n",
       "         ...,\n",
       "         [237, 232, 219],\n",
       "         [223, 219, 222],\n",
       "         [214, 210, 219]],\n",
       "\n",
       "        [[170, 238, 234],\n",
       "         [178, 241, 236],\n",
       "         [194, 246, 235],\n",
       "         ...,\n",
       "         [234, 232, 227],\n",
       "         [218, 215, 225],\n",
       "         [209, 204, 221]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[200, 196, 171],\n",
       "         [198, 202, 171],\n",
       "         [194, 213, 172],\n",
       "         ...,\n",
       "         [120, 145, 184],\n",
       "         [119, 144, 183],\n",
       "         [119, 143, 184]],\n",
       "\n",
       "        [[201, 183, 166],\n",
       "         [200, 192, 168],\n",
       "         [198, 210, 173],\n",
       "         ...,\n",
       "         [112, 130, 165],\n",
       "         [109, 127, 163],\n",
       "         [108, 127, 165]],\n",
       "\n",
       "        [[201, 175, 159],\n",
       "         [201, 186, 163],\n",
       "         [200, 208, 171],\n",
       "         ...,\n",
       "         [110, 125, 158],\n",
       "         [106, 122, 157],\n",
       "         [105, 122, 161]]]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for image_get in X_test_img:\n",
    "    img_test = cv2.imread(img_folder + '{}.jpg'.format(image_get))\n",
    "    \n",
    "    img_test = cv2.resize(img_test,(100,75))\n",
    "    #img_test = img_test[0:224  ,  38:262]\n",
    "    \n",
    "    R,G,B = cv2.split(img_test)\n",
    "    R_new = cv2.equalizeHist(R)\n",
    "    G_new = cv2.equalizeHist(G)\n",
    "    B_new = cv2.equalizeHist(B)\n",
    "    \n",
    "    img_test = cv2.merge([R_new,G_new,B_new])\n",
    "    img_test = cv2.GaussianBlur(img_test,(5,5),0)\n",
    "  \n",
    "    X_test.append(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array data to float32\n",
    "X_train = X_train.astype(np.float32)\n",
    "\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[166., 231., 225.],\n",
       "         [176., 236., 230.],\n",
       "         [197., 244., 237.],\n",
       "         ...,\n",
       "         [238., 232., 215.],\n",
       "         [225., 221., 221.],\n",
       "         [216., 213., 220.]],\n",
       "\n",
       "        [[168., 234., 228.],\n",
       "         [177., 237., 232.],\n",
       "         [196., 245., 236.],\n",
       "         ...,\n",
       "         [237., 232., 219.],\n",
       "         [223., 219., 222.],\n",
       "         [214., 210., 219.]],\n",
       "\n",
       "        [[170., 238., 234.],\n",
       "         [178., 241., 236.],\n",
       "         [194., 246., 235.],\n",
       "         ...,\n",
       "         [234., 232., 227.],\n",
       "         [218., 215., 225.],\n",
       "         [209., 204., 221.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[200., 196., 171.],\n",
       "         [198., 202., 171.],\n",
       "         [194., 213., 172.],\n",
       "         ...,\n",
       "         [120., 145., 184.],\n",
       "         [119., 144., 183.],\n",
       "         [119., 143., 184.]],\n",
       "\n",
       "        [[201., 183., 166.],\n",
       "         [200., 192., 168.],\n",
       "         [198., 210., 173.],\n",
       "         ...,\n",
       "         [112., 130., 165.],\n",
       "         [109., 127., 163.],\n",
       "         [108., 127., 165.]],\n",
       "\n",
       "        [[201., 175., 159.],\n",
       "         [201., 186., 163.],\n",
       "         [200., 208., 171.],\n",
       "         ...,\n",
       "         [110., 125., 158.],\n",
       "         [106., 122., 157.],\n",
       "         [105., 122., 161.]]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to float between 0 and 1 (256 per channel)\n",
    "X_train /=255\n",
    "\n",
    "X_test /=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.6509804 , 0.90588236, 0.88235295],\n",
       "         [0.6901961 , 0.9254902 , 0.9019608 ],\n",
       "         [0.77254903, 0.95686275, 0.92941177],\n",
       "         ...,\n",
       "         [0.93333334, 0.9098039 , 0.84313726],\n",
       "         [0.88235295, 0.8666667 , 0.8666667 ],\n",
       "         [0.84705883, 0.8352941 , 0.8627451 ]],\n",
       "\n",
       "        [[0.65882355, 0.91764706, 0.89411765],\n",
       "         [0.69411767, 0.92941177, 0.9098039 ],\n",
       "         [0.76862746, 0.9607843 , 0.9254902 ],\n",
       "         ...,\n",
       "         [0.92941177, 0.9098039 , 0.85882354],\n",
       "         [0.8745098 , 0.85882354, 0.87058824],\n",
       "         [0.8392157 , 0.8235294 , 0.85882354]],\n",
       "\n",
       "        [[0.6666667 , 0.93333334, 0.91764706],\n",
       "         [0.69803923, 0.94509804, 0.9254902 ],\n",
       "         [0.7607843 , 0.9647059 , 0.92156863],\n",
       "         ...,\n",
       "         [0.91764706, 0.9098039 , 0.8901961 ],\n",
       "         [0.85490197, 0.84313726, 0.88235295],\n",
       "         [0.81960785, 0.8       , 0.8666667 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.78431374, 0.76862746, 0.67058825],\n",
       "         [0.7764706 , 0.7921569 , 0.67058825],\n",
       "         [0.7607843 , 0.8352941 , 0.6745098 ],\n",
       "         ...,\n",
       "         [0.47058824, 0.5686275 , 0.72156864],\n",
       "         [0.46666667, 0.5647059 , 0.7176471 ],\n",
       "         [0.46666667, 0.56078434, 0.72156864]],\n",
       "\n",
       "        [[0.7882353 , 0.7176471 , 0.6509804 ],\n",
       "         [0.78431374, 0.7529412 , 0.65882355],\n",
       "         [0.7764706 , 0.8235294 , 0.6784314 ],\n",
       "         ...,\n",
       "         [0.4392157 , 0.50980395, 0.64705884],\n",
       "         [0.42745098, 0.49803922, 0.6392157 ],\n",
       "         [0.42352942, 0.49803922, 0.64705884]],\n",
       "\n",
       "        [[0.7882353 , 0.6862745 , 0.62352943],\n",
       "         [0.7882353 , 0.7294118 , 0.6392157 ],\n",
       "         [0.78431374, 0.8156863 , 0.67058825],\n",
       "         ...,\n",
       "         [0.43137255, 0.49019608, 0.61960787],\n",
       "         [0.41568628, 0.47843137, 0.6156863 ],\n",
       "         [0.4117647 , 0.47843137, 0.6313726 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9932, 75, 100, 3) (1002, 75, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_image = X_train\n",
    "X_test_image = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to process the text data from the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1815</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5144</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  sex  localization\n",
       "2834  1.000000  0.0          0.00\n",
       "5719  0.000000  0.0          0.63\n",
       "1815  0.352941  0.0          0.14\n",
       "5144  0.470588  0.0          0.00\n",
       "1     0.882353  1.0          0.14"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training text dataframe to numpy values\n",
    "\n",
    "X_train_data = X_train_data.values\n",
    "\n",
    "X_test_data = X_test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9932, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_data[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training text dataframe to values for numpy\n",
    "\n",
    "Y_train_data = Y_train_data.values\n",
    "\n",
    "Y_test_data = Y_test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 1., 2., 1., 6.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_data = Y_train_data.reshape(-1,1)\n",
    "\n",
    "Y_test_data = Y_test_data.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [6.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the classifications in the Y data\n",
    "encoder_train = OneHotEncoder(sparse=False, categories='auto')\n",
    "Y_train_data = encoder_train.fit_transform(Y_train_data)\n",
    "\n",
    "encoder_test = OneHotEncoder(sparse=False, categories='auto')\n",
    "Y_test_data = encoder_test.fit_transform(Y_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the tabular data to the optimum model on its own, getting the ANN sizing, optimization model and learning rate at an optimum level, and save the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set filepath to save weights for text data into\n",
    "\n",
    "text_weights_filepath = 'TF Keras Concat Weights Text.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up checkpoint to record best weights\n",
    "\n",
    "checkpoint = ModelCheckpoint(text_weights_filepath, monitor='val_acc',\n",
    "                            verbose=1, save_best_only=True)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9932, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9932, 7)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ANN Model for text data using API\n",
    "\n",
    "text_inputs = keras.Input(shape=(3,))\n",
    "\n",
    "x_text = keras.layers.Dense(60, activation = 'relu')(text_inputs)\n",
    "x_text = keras.layers.Dropout(0.2)(x_text)\n",
    "x_text = keras.layers.Flatten()(x_text)\n",
    "\n",
    "x_text = keras.layers.Dense(480, activation = 'relu')(x_text)\n",
    "x_text = keras.layers.Dropout(0.3)(x_text)\n",
    "x_text = keras.layers.Flatten()(x_text)\n",
    "\n",
    "x_text = keras.layers.Dense(240, activation = 'relu')(x_text)\n",
    "x_text = keras.layers.Dropout(0.2)(x_text)\n",
    "x_text = keras.layers.Flatten()(x_text)\n",
    "\n",
    "x_text_output = keras.layers.Dense(7, activation='softmax')(x_text)\n",
    "\n",
    "text_model = keras.models.Model(text_inputs, x_text_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 480)               29280     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 240)               115440    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 240)               0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 240)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 1687      \n",
      "=================================================================\n",
      "Total params: 146,647\n",
      "Trainable params: 146,647\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with parameters\n",
    "\n",
    "text_model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9932 samples, validate on 1002 samples\n",
      "Epoch 1/25\n",
      "9088/9932 [==========================>...] - ETA: 0s - loss: 1.7054 - acc: 0.5511\n",
      "Epoch 00001: val_acc improved from -inf to 0.66866, saving model to TF Keras Concat Weights Text.hdf5\n",
      "9932/9932 [==============================] - 1s 96us/sample - loss: 1.6850 - acc: 0.5557 - val_loss: 1.3295 - val_acc: 0.6687\n",
      "Epoch 2/25\n",
      "9472/9932 [===========================>..] - ETA: 0s - loss: 1.4243 - acc: 0.6054\n",
      "Epoch 00002: val_acc did not improve from 0.66866\n",
      "9932/9932 [==============================] - 0s 24us/sample - loss: 1.4283 - acc: 0.6031 - val_loss: 1.2404 - val_acc: 0.6687\n",
      "Epoch 3/25\n",
      "8960/9932 [==========================>...] - ETA: 0s - loss: 1.4009 - acc: 0.6050\n",
      "Epoch 00003: val_acc did not improve from 0.66866\n",
      "9932/9932 [==============================] - 0s 25us/sample - loss: 1.4014 - acc: 0.6031 - val_loss: 1.2179 - val_acc: 0.6687\n",
      "Epoch 4/25\n",
      "8704/9932 [=========================>....] - ETA: 0s - loss: 1.3746 - acc: 0.6057\n",
      "Epoch 00004: val_acc did not improve from 0.66866\n",
      "9932/9932 [==============================] - 0s 26us/sample - loss: 1.3800 - acc: 0.6031 - val_loss: 1.1886 - val_acc: 0.6687\n",
      "Epoch 5/25\n",
      "8320/9932 [========================>.....] - ETA: 0s - loss: 1.3581 - acc: 0.6043\n",
      "Epoch 00005: val_acc did not improve from 0.66866\n",
      "9932/9932 [==============================] - 0s 27us/sample - loss: 1.3577 - acc: 0.6031 - val_loss: 1.1674 - val_acc: 0.6687\n",
      "Epoch 6/25\n",
      "8832/9932 [=========================>....] - ETA: 0s - loss: 1.3381 - acc: 0.6016\n",
      "Epoch 00006: val_acc did not improve from 0.66866\n",
      "9932/9932 [==============================] - 0s 26us/sample - loss: 1.3330 - acc: 0.6031 - val_loss: 1.1304 - val_acc: 0.6687\n",
      "Epoch 7/25\n",
      "8704/9932 [=========================>....] - ETA: 0s - loss: 1.3210 - acc: 0.5998\n",
      "Epoch 00007: val_acc did not improve from 0.66866\n",
      "9932/9932 [==============================] - 0s 26us/sample - loss: 1.3152 - acc: 0.6032 - val_loss: 1.1071 - val_acc: 0.6687\n",
      "Epoch 8/25\n",
      "8832/9932 [=========================>....] - ETA: 0s - loss: 1.3003 - acc: 0.6027\n",
      "Epoch 00008: val_acc improved from 0.66866 to 0.67166, saving model to TF Keras Concat Weights Text.hdf5\n",
      "9932/9932 [==============================] - 0s 28us/sample - loss: 1.2971 - acc: 0.6040 - val_loss: 1.0904 - val_acc: 0.6717\n",
      "Epoch 9/25\n",
      "8832/9932 [=========================>....] - ETA: 0s - loss: 1.2854 - acc: 0.6028\n",
      "Epoch 00009: val_acc improved from 0.67166 to 0.67265, saving model to TF Keras Concat Weights Text.hdf5\n",
      "9932/9932 [==============================] - 0s 28us/sample - loss: 1.2828 - acc: 0.6039 - val_loss: 1.0754 - val_acc: 0.6727\n",
      "Epoch 10/25\n",
      "9728/9932 [============================>.] - ETA: 0s - loss: 1.2747 - acc: 0.6041\n",
      "Epoch 00010: val_acc did not improve from 0.67265\n",
      "9932/9932 [==============================] - 0s 23us/sample - loss: 1.2745 - acc: 0.6041 - val_loss: 1.0644 - val_acc: 0.6707\n",
      "Epoch 11/25\n",
      "7680/9932 [======================>.......] - ETA: 0s - loss: 1.2556 - acc: 0.6091\n",
      "Epoch 00011: val_acc improved from 0.67265 to 0.67465, saving model to TF Keras Concat Weights Text.hdf5\n",
      "9932/9932 [==============================] - 0s 24us/sample - loss: 1.2666 - acc: 0.6058 - val_loss: 1.0607 - val_acc: 0.6747\n",
      "Epoch 12/25\n",
      "7936/9932 [======================>.......] - ETA: 0s - loss: 1.2647 - acc: 0.6038\n",
      "Epoch 00012: val_acc did not improve from 0.67465\n",
      "9932/9932 [==============================] - 0s 21us/sample - loss: 1.2625 - acc: 0.6045 - val_loss: 1.0525 - val_acc: 0.6747\n",
      "Epoch 13/25\n",
      "7552/9932 [=====================>........] - ETA: 0s - loss: 1.2478 - acc: 0.6092\n",
      "Epoch 00013: val_acc did not improve from 0.67465\n",
      "9932/9932 [==============================] - 0s 23us/sample - loss: 1.2562 - acc: 0.6062 - val_loss: 1.0503 - val_acc: 0.6737\n",
      "Epoch 14/25\n",
      "7552/9932 [=====================>........] - ETA: 0s - loss: 1.2532 - acc: 0.6057\n",
      "Epoch 00014: val_acc did not improve from 0.67465\n",
      "9932/9932 [==============================] - 0s 22us/sample - loss: 1.2546 - acc: 0.6050 - val_loss: 1.0409 - val_acc: 0.6747\n",
      "Epoch 15/25\n",
      "7936/9932 [======================>.......] - ETA: 0s - loss: 1.2455 - acc: 0.6099\n",
      "Epoch 00015: val_acc did not improve from 0.67465\n",
      "9932/9932 [==============================] - 0s 21us/sample - loss: 1.2521 - acc: 0.6061 - val_loss: 1.0409 - val_acc: 0.6747\n",
      "Epoch 16/25\n",
      "9856/9932 [============================>.] - ETA: 0s - loss: 1.2487 - acc: 0.6054\n",
      "Epoch 00016: val_acc did not improve from 0.67465\n",
      "9932/9932 [==============================] - 0s 23us/sample - loss: 1.2485 - acc: 0.6056 - val_loss: 1.0367 - val_acc: 0.6737\n",
      "Epoch 17/25\n",
      "7552/9932 [=====================>........] - ETA: 0s - loss: 1.2427 - acc: 0.6063\n",
      "Epoch 00017: val_acc improved from 0.67465 to 0.67565, saving model to TF Keras Concat Weights Text.hdf5\n",
      "9932/9932 [==============================] - 0s 25us/sample - loss: 1.2461 - acc: 0.6067 - val_loss: 1.0361 - val_acc: 0.6756\n",
      "Epoch 18/25\n",
      "9344/9932 [===========================>..] - ETA: 0s - loss: 1.2468 - acc: 0.6038\n",
      "Epoch 00018: val_acc did not improve from 0.67565\n",
      "9932/9932 [==============================] - 0s 24us/sample - loss: 1.2419 - acc: 0.6055 - val_loss: 1.0337 - val_acc: 0.6737\n",
      "Epoch 19/25\n",
      "9856/9932 [============================>.] - ETA: 0s - loss: 1.2412 - acc: 0.6078\n",
      "Epoch 00019: val_acc did not improve from 0.67565\n",
      "9932/9932 [==============================] - 0s 23us/sample - loss: 1.2412 - acc: 0.6077 - val_loss: 1.0348 - val_acc: 0.6737\n",
      "Epoch 20/25\n",
      "7552/9932 [=====================>........] - ETA: 0s - loss: 1.2382 - acc: 0.6075\n",
      "Epoch 00020: val_acc did not improve from 0.67565\n",
      "9932/9932 [==============================] - 0s 23us/sample - loss: 1.2403 - acc: 0.6057 - val_loss: 1.0299 - val_acc: 0.6737\n",
      "Epoch 21/25\n",
      "9088/9932 [==========================>...] - ETA: 0s - loss: 1.2398 - acc: 0.6095\n",
      "Epoch 00021: val_acc did not improve from 0.67565\n",
      "9932/9932 [==============================] - 0s 25us/sample - loss: 1.2384 - acc: 0.6082 - val_loss: 1.0274 - val_acc: 0.6747\n",
      "Epoch 22/25\n",
      "9600/9932 [===========================>..] - ETA: 0s - loss: 1.2356 - acc: 0.6064\n",
      "Epoch 00022: val_acc improved from 0.67565 to 0.67665, saving model to TF Keras Concat Weights Text.hdf5\n",
      "9932/9932 [==============================] - 0s 26us/sample - loss: 1.2371 - acc: 0.6058 - val_loss: 1.0296 - val_acc: 0.6766\n",
      "Epoch 23/25\n",
      "9472/9932 [===========================>..] - ETA: 0s - loss: 1.2376 - acc: 0.6048\n",
      "Epoch 00023: val_acc did not improve from 0.67665\n",
      "9932/9932 [==============================] - 0s 24us/sample - loss: 1.2341 - acc: 0.6061 - val_loss: 1.0264 - val_acc: 0.6756\n",
      "Epoch 24/25\n",
      "7680/9932 [======================>.......] - ETA: 0s - loss: 1.2331 - acc: 0.6035\n",
      "Epoch 00024: val_acc did not improve from 0.67665\n",
      "9932/9932 [==============================] - 0s 22us/sample - loss: 1.2315 - acc: 0.6064 - val_loss: 1.0309 - val_acc: 0.6766\n",
      "Epoch 25/25\n",
      "7808/9932 [======================>.......] - ETA: 0s - loss: 1.2196 - acc: 0.6108\n",
      "Epoch 00025: val_acc did not improve from 0.67665\n",
      "9932/9932 [==============================] - 0s 22us/sample - loss: 1.2279 - acc: 0.6074 - val_loss: 1.0275 - val_acc: 0.6727\n"
     ]
    }
   ],
   "source": [
    "# Fit the text data model\n",
    "\n",
    "history = text_model.fit(X_train_data, Y_train_data, \n",
    "    epochs=25, \n",
    "    batch_size=128,\n",
    "    validation_data=(X_test_data, Y_test_data), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a8faa2750>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, acc, 'r')\n",
    "plt.plot(epochs, val_acc, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_model.predict([X_test_data, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_data_decode = np.argmax(Y_test_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_decode = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14  97   0   0   0   0   0]\n",
      " [ 10 660   0   0   0   0   0]\n",
      " [  0  11   0   0   0   0   0]\n",
      " [ 15  97   0   0   0   0   0]\n",
      " [  2  15   0   0   0   0   0]\n",
      " [ 15  33   0   0   0   0   0]\n",
      " [  2  31   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test_data_decode, predictions_decode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.13      0.17       111\n",
      "           1       0.70      0.99      0.82       670\n",
      "           2       0.00      0.00      0.00        11\n",
      "           3       0.00      0.00      0.00       112\n",
      "           4       0.00      0.00      0.00        17\n",
      "           5       0.00      0.00      0.00        48\n",
      "           6       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.67      1002\n",
      "   macro avg       0.13      0.16      0.14      1002\n",
      "weighted avg       0.49      0.67      0.57      1002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philgodley/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test_data_decode, predictions_decode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Do the same with the CNN on its own, again, saving the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set filepath to save weights for text data into\n",
    "\n",
    "image_weights_filepath = 'TF Keras Concat Weights Image.hdf5'\n",
    "\n",
    "# Set up checkpoint to record best weights\n",
    "\n",
    "checkpoint = ModelCheckpoint(image_weights_filepath, monitor='val_acc',\n",
    "                            verbose=1, save_best_only=True)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 75, 100, 3)]      0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 75, 100, 64)       1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 75, 100, 64)       36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 37, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 37, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 37, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 18, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 18, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 18, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 18, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 9, 12, 256)        0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 9, 12, 512)        1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 9, 12, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 9, 12, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 3, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# image_inputs = keras.Input(shape=(75,100,3))\n",
    "# CNN Model for images\n",
    "\n",
    "pre_trained_model= VGG16(input_shape=(75, 100, 3),\n",
    "                        include_top = False,\n",
    "                        weights = 'imagenet')\n",
    "\n",
    "for layer in pre_trained_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the model to requirements...\n",
    "\n",
    "outer_layer = pre_trained_model.get_layer('block5_pool')\n",
    "outer_input = outer_layer.output\n",
    "\n",
    "x_image = keras.layers.Flatten()(outer_input)\n",
    "x_image = keras.layers.Dense(1000, activation='relu')(x_image)\n",
    "x_image = keras.layers.Dense(64, activation='relu')(x_image)\n",
    "\n",
    "x_image_output = keras.layers.Dense(7, activation='softmax')(x_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 75, 100, 3)]      0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 75, 100, 64)       1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 75, 100, 64)       36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 37, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 37, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 37, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 18, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 18, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 18, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 18, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 9, 12, 256)        0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 9, 12, 512)        1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 9, 12, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 9, 12, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1000)              3073000   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                64064     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 17,852,207\n",
      "Trainable params: 3,137,519\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_model = keras.models.Model(pre_trained_model.input, x_image_output)\n",
    "\n",
    "image_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "\n",
    "image_model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9932 samples, validate on 1002 samples\n",
      "9856/9932 [============================>.] - ETA: 0s - loss: 0.9860 - acc: 0.6520\n",
      "Epoch 00001: val_acc improved from 0.70958 to 0.72056, saving model to TF Keras Concat Weights Concat.hdf5\n",
      "9932/9932 [==============================] - 135s 14ms/sample - loss: 0.9839 - acc: 0.6528 - val_loss: 0.8243 - val_acc: 0.7206\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "\n",
    "image_history = image_model.fit(X_train_image, Y_train_data, \n",
    "    epochs=1, \n",
    "    batch_size=128,\n",
    "    validation_data=(X_test_image, Y_test_data), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = image_history.history['acc']\n",
    "val_acc = image_history.history['val_acc']\n",
    "loss = image_history.history['loss']\n",
    "val_loss = image_history.history['val_loss']\n",
    "epochs = range(len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a936a5cd0>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, acc, 'r')\n",
    "plt.plot(epochs, val_acc, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a90ab94d0>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, loss, 'r')\n",
    "plt.plot(epochs, val_loss, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = image_model.predict(X_test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_data_decode = np.argmax(Y_test_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_decode = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 24  76   0  10   0   1   0]\n",
      " [  2 658   2   7   0   0   1]\n",
      " [  1   6   3   1   0   0   0]\n",
      " [  5  82   1  23   1   0   0]\n",
      " [  0  14   0   1   1   1   0]\n",
      " [  7  28   3   2   0   4   4]\n",
      " [  6  13   0   3   0   2   9]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test_data_decode, predictions_decode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.22      0.31       111\n",
      "           1       0.75      0.98      0.85       670\n",
      "           2       0.33      0.27      0.30        11\n",
      "           3       0.49      0.21      0.29       112\n",
      "           4       0.50      0.06      0.11        17\n",
      "           5       0.50      0.08      0.14        48\n",
      "           6       0.64      0.27      0.38        33\n",
      "\n",
      "    accuracy                           0.72      1002\n",
      "   macro avg       0.54      0.30      0.34      1002\n",
      "weighted avg       0.67      0.72      0.66      1002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test_data_decode, predictions_decode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run the concatenated model, but this time, do not allow the tabular data nor the CNN weights to be trained. i.e. you can only update the weights on the final layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set filepath to save weights for text data into\n",
    "\n",
    "concat_weights_filepath = 'TF Keras Concat Weights Concat.hdf5'\n",
    "\n",
    "# Set up checkpoint to record best weights\n",
    "\n",
    "checkpoint = ModelCheckpoint(concat_weights_filepath, monitor='val_acc',\n",
    "                            verbose=1, save_best_only=True)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your concatenated model\n",
    "\n",
    "concatenated = keras.layers.concatenate([x_text ,x_image], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = keras.layers.Dense(7, activation='softmax')(concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model\n",
    "\n",
    "concat_model = keras.models.Model([text_model.input, image_model.input], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in concat_model.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 75, 100, 3)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 75, 100, 64)  1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 75, 100, 64)  36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 37, 50, 64)   0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 37, 50, 128)  73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 37, 50, 128)  147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 18, 25, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 18, 25, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 18, 25, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 18, 25, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 9, 12, 256)   0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 9, 12, 512)   1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 9, 12, 512)   2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 60)           240         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 9, 12, 512)   2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 60)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 4, 6, 512)    0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 60)           0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 4, 6, 512)    2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 480)          29280       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 4, 6, 512)    2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 480)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 4, 6, 512)    2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 480)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 2, 3, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 240)          115440      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 3072)         0           block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 240)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1000)         3073000     flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 240)          0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           64064       dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 304)          0           flatten_2[0][0]                  \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 7)            2135        concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 17,998,847\n",
      "Trainable params: 2,135\n",
      "Non-trainable params: 17,996,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "concat_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights\n",
    "# concat_model.load_weights(['TF Keras Concat Weights Text.hdf5', 'TF Keras Concat Weights Image.hdf5'], by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9932 samples, validate on 1002 samples\n",
      "Epoch 1/10\n",
      "9856/9932 [============================>.] - ETA: 0s - loss: 1.0820 - acc: 0.6238\n",
      "Epoch 00001: val_acc did not improve from 0.69261\n",
      "9932/9932 [==============================] - 133s 13ms/sample - loss: 1.0810 - acc: 0.6242 - val_loss: 0.9147 - val_acc: 0.6916\n",
      "Epoch 2/10\n",
      "9856/9932 [============================>.] - ETA: 0s - loss: 1.0726 - acc: 0.6239\n",
      "Epoch 00002: val_acc improved from 0.69261 to 0.69361, saving model to TF Keras Concat Weights Concat.hdf5\n",
      "9932/9932 [==============================] - 131s 13ms/sample - loss: 1.0720 - acc: 0.6242 - val_loss: 0.9101 - val_acc: 0.6936\n",
      "Epoch 3/10\n",
      "9856/9932 [============================>.] - ETA: 0s - loss: 1.0674 - acc: 0.6260\n",
      "Epoch 00003: val_acc improved from 0.69361 to 0.69461, saving model to TF Keras Concat Weights Concat.hdf5\n",
      "9932/9932 [==============================] - 136s 14ms/sample - loss: 1.0674 - acc: 0.6263 - val_loss: 0.9052 - val_acc: 0.6946\n",
      "Epoch 4/10\n",
      "9856/9932 [============================>.] - ETA: 0s - loss: 1.0605 - acc: 0.6249\n",
      "Epoch 00004: val_acc did not improve from 0.69461\n",
      "9932/9932 [==============================] - 133s 13ms/sample - loss: 1.0619 - acc: 0.6243 - val_loss: 0.9015 - val_acc: 0.6946\n",
      "Epoch 5/10\n",
      "9856/9932 [============================>.] - ETA: 0s - loss: 1.0573 - acc: 0.6265\n",
      "Epoch 00005: val_acc improved from 0.69461 to 0.69661, saving model to TF Keras Concat Weights Concat.hdf5\n",
      "9932/9932 [==============================] - 134s 13ms/sample - loss: 1.0572 - acc: 0.6268 - val_loss: 0.8979 - val_acc: 0.6966\n",
      "Epoch 6/10\n",
      "9856/9932 [============================>.] - ETA: 0s - loss: 1.0517 - acc: 0.6279\n",
      "Epoch 00006: val_acc improved from 0.69661 to 0.69960, saving model to TF Keras Concat Weights Concat.hdf5\n",
      "9932/9932 [==============================] - 131s 13ms/sample - loss: 1.0521 - acc: 0.6278 - val_loss: 0.8952 - val_acc: 0.6996\n",
      "Epoch 7/10\n",
      "9856/9932 [============================>.] - ETA: 0s - loss: 1.0464 - acc: 0.6292\n",
      "Epoch 00007: val_acc improved from 0.69960 to 0.70659, saving model to TF Keras Concat Weights Concat.hdf5\n",
      "9932/9932 [==============================] - 132s 13ms/sample - loss: 1.0462 - acc: 0.6294 - val_loss: 0.8918 - val_acc: 0.7066\n",
      "Epoch 8/10\n",
      "9856/9932 [============================>.] - ETA: 0s - loss: 1.0422 - acc: 0.6276\n",
      "Epoch 00008: val_acc improved from 0.70659 to 0.70758, saving model to TF Keras Concat Weights Concat.hdf5\n",
      "9932/9932 [==============================] - 132s 13ms/sample - loss: 1.0422 - acc: 0.6273 - val_loss: 0.8895 - val_acc: 0.7076\n",
      "Epoch 9/10\n",
      "9856/9932 [============================>.] - ETA: 0s - loss: 1.0357 - acc: 0.6320\n",
      "Epoch 00009: val_acc improved from 0.70758 to 0.70858, saving model to TF Keras Concat Weights Concat.hdf5\n",
      "9932/9932 [==============================] - 131s 13ms/sample - loss: 1.0369 - acc: 0.6314 - val_loss: 0.8861 - val_acc: 0.7086\n",
      "Epoch 10/10\n",
      "9856/9932 [============================>.] - ETA: 0s - loss: 1.0328 - acc: 0.6308\n",
      "Epoch 00010: val_acc improved from 0.70858 to 0.70958, saving model to TF Keras Concat Weights Concat.hdf5\n",
      "9932/9932 [==============================] - 131s 13ms/sample - loss: 1.0326 - acc: 0.6306 - val_loss: 0.8837 - val_acc: 0.7096\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "concat_history = concat_model.fit(\n",
    "    [X_train_data, X_train_image], Y_train_data, \n",
    "    epochs=10, \n",
    "    batch_size=128,\n",
    "    validation_data=([X_test_data, X_test_image], Y_test_data), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a94c37f90>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, acc, 'r')\n",
    "plt.plot(epochs, val_acc, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a948887d0>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, loss, 'r')\n",
    "plt.plot(epochs, val_loss, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = concat_model.predict([X_test_data, X_test_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_data_decode = np.argmax(Y_test_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_decode = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 20  86   0   2   0   3   0]\n",
      " [  2 668   0   0   0   0   0]\n",
      " [  1   9   0   1   0   0   0]\n",
      " [  6  99   0   5   0   2   0]\n",
      " [  0  17   0   0   0   0   0]\n",
      " [ 10  27   0   3   0   7   1]\n",
      " [ 11  20   0   0   0   2   0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test_data_decode, predictions_decode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.18      0.25       111\n",
      "           1       0.72      1.00      0.84       670\n",
      "           2       0.00      0.00      0.00        11\n",
      "           3       0.45      0.04      0.08       112\n",
      "           4       0.00      0.00      0.00        17\n",
      "           5       0.50      0.15      0.23        48\n",
      "           6       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.70      1002\n",
      "   macro avg       0.30      0.20      0.20      1002\n",
      "weighted avg       0.60      0.70      0.61      1002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philgodley/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test_data_decode, predictions_decode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
